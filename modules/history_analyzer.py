import json
from collections import defaultdict
from .logger_manager import get_logger
from .visualization import create_visualizations

logger = get_logger()

def create_item_mapping(catalog_data):
    """åˆ›å»ºç‰©å“åç§°åˆ°è¯¦æƒ…çš„æ˜ å°„"""
    item_mapping = {}
    for item_id, item_info in catalog_data.get('item', {}).items():
        display_name = item_info.get('display_name', '')
        item_mapping[display_name] = {
            'id': item_id,
            'rarity': item_info.get('rarity', 0),
            'item_type': item_info.get('item_type', '')
        }
    return item_mapping

def create_pool_mapping(catalog_data):
    """åˆ›å»ºå¡æ± åç§°åˆ°è¯¦æƒ…çš„æ˜ å°„"""
    pool_mapping = {}
    for pool_id, pool_info in catalog_data.get('pool', {}).items():
        display_name = pool_info.get('display_name', '')
        pool_mapping[display_name] = {
            'id': pool_id,
            'pool_type': pool_info.get('pool_type', ''),
            'alias': pool_info.get('alias', ''),
            'carry_over': pool_info.get('carry_over', False),
            'carry_over_target': pool_info.get('carry_over_target', [])
        }
    return pool_mapping

def analyze_gacha_data(gacha_data, catalog_data):
    """åˆ†ææŠ½å¡æ•°æ®é€»è¾‘"""
    # åˆ›å»ºæ˜ å°„
    item_mapping = create_item_mapping(catalog_data)
    pool_mapping = create_pool_mapping(catalog_data)

    # åˆå§‹åŒ–ç»Ÿè®¡æ•°æ®ç»“æ„
    pool_stats = defaultdict(lambda: {
        'total_pulls': 0,
        'rarity_counts': {rarity: 0 for rarity in range(2, 7)},
        'pull_history': [],  # è®°å½•æ¯æ¬¡æŠ½å–çš„è¯¦æƒ…
        'gold_pulls': [],   # è®°å½•æ¯æ¬¡å‡º6æ˜Ÿçš„æŠ½æ•°é—´éš”
        'last_gold_pull': -1,  # ä¸Šæ¬¡å‡º6æ˜Ÿçš„ç´¢å¼•
        'current_pity': 0,   # å½“å‰ä¿åº•è®¡æ•°
        'items': []         # æŠ½å–åˆ°çš„ç‰©å“åˆ—è¡¨
    })

    # æŒ‰æ—¶é—´æ’åºï¼ˆå‡è®¾æ•°æ®å·²ç»æŒ‰æ—¶é—´æ’åºï¼Œä½†ä¸ºäº†å®‰å…¨è¿˜æ˜¯æ’åºï¼‰
    gacha_entries = sorted(gacha_data['data'], key=lambda x: x['time'])

    # éå†æŠ½å¡è®°å½•
    for idx, entry in enumerate(gacha_entries):
        item_name = entry['item']
        pool_name = entry['pool']

        # è·å–ç‰©å“ç¨€æœ‰åº¦
        item_info = item_mapping.get(item_name, {})
        rarity = item_info.get('rarity', 0)

        # æ›´æ–°å¡æ± ç»Ÿè®¡
        pool_stats[pool_name]['total_pulls'] += 1
        # æ£€æŸ¥ç¨€æœ‰åº¦æ˜¯å¦åœ¨æœ‰æ•ˆèŒƒå›´å†…ï¼Œå¦åˆ™è·³è¿‡æˆ–è®°å½•ä¸ºå…¶ä»–
        if rarity in pool_stats[pool_name]['rarity_counts']:
            pool_stats[pool_name]['rarity_counts'][rarity] += 1
        else:
            # å¦‚æœç¨€æœ‰åº¦ä¸åœ¨é¢„æœŸèŒƒå›´å†…ï¼ˆå¦‚0æˆ–å…¶ä»–å€¼ï¼‰ï¼Œå¯ä»¥é€‰æ‹©å¿½ç•¥æˆ–æ·»åŠ åˆ°ç‰¹å®šç±»åˆ«
            if rarity != 0:  # ä»…å¯¹é0ä½†æ— æ•ˆçš„ç¨€æœ‰åº¦å‘å‡ºè­¦å‘Š
                logger.warning(f"å‘ç°æ— æ•ˆç¨€æœ‰åº¦å€¼ {rarity}ï¼Œç‰©å“åç§°: {item_name}")
        
        pool_stats[pool_name]['pull_history'].append({
            'item': item_name,
            'rarity': rarity,
            'time': entry['time'],
            'pull_number': pool_stats[pool_name]['total_pulls']
        })
        pool_stats[pool_name]['items'].append(item_name)

        # æ›´æ–°ä¿åº•è®¡æ•°
        pool_stats[pool_name]['current_pity'] += 1

        # æ£€æŸ¥æ˜¯å¦å‡º6æ˜Ÿ
        if rarity == 6:
            # è®°å½•å½“å‰çš„æŠ½æ•°
            pool_stats[pool_name]['gold_pulls'].append(pool_stats[pool_name]['current_pity'])
            pool_stats[pool_name]['last_gold_pull'] = idx
            pool_stats[pool_name]['current_pity'] = 0

    return pool_stats, item_mapping, pool_mapping


def calculate_statistics(pool_stats):
    """è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡"""
    results = {}
    
    for pool_name, stats in pool_stats.items():
        total_pulls = stats['total_pulls']
        rarity_counts = stats['rarity_counts']
        gold_pulls = stats['gold_pulls']
        
        # 1. æ€»æŠ½å–æ¬¡æ•°
        total_pulls = stats['total_pulls']
        
        # 2. ç¨€æœ‰åº¦åˆ†å¸ƒ
        rarity_distribution = {
            '2_star': rarity_counts[2],
            '3_star': rarity_counts[3],
            '4_star': rarity_counts[4],
            '5_star': rarity_counts[5],
            '6_star': rarity_counts[6]
        }
        
        # 3. ä¿åº•è¿›åº¦
        pity_progress = stats['current_pity']
        
        # 4. å‡ºé‡‘ç‡
        gold_rate = rarity_counts[6] / total_pulls * 100 if total_pulls > 0 else 0
        
        results[pool_name] = {
            'total_pulls': total_pulls,
            'rarity_distribution': rarity_distribution,
            'pity_progress': pity_progress,
            'gold_pulls_history': gold_pulls,
            'gold_rate': gold_rate,
            'rarity_counts': rarity_counts
        }
    
    return results


def analysis_report(results, pool_stats, pool_mapping, game_name, uid):
    current_logger = get_logger()
    report_lines = []
    report_lines.append("=" * 60)
    report_lines.append(f"{game_name}æŠ½å¡è®°å½•åˆ†ææŠ¥å‘Š")
    report_lines.append(f"ç”¨æˆ·UID: {uid}")
    report_lines.append("=" * 60)

    total_pulls_all = sum(stats['total_pulls'] for stats in pool_stats.values())
    total_6_star = sum(stats['rarity_counts'][6] for stats in pool_stats.values())

    report_lines.append(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    report_lines.append(f"   æ€»æŠ½å–æ¬¡æ•°: {total_pulls_all}æ¬¡")
    report_lines.append(f"   6æ˜Ÿè·å–æ•°é‡: {total_6_star}ä¸ª")
    if total_pulls_all > 0:
        report_lines.append(f"   ç»¼åˆ6æ˜Ÿè·å–ç‡: {total_6_star/total_pulls_all*100:.2f}%")
    else:
        report_lines.append(f"   å°šæœªè·å¾—6æ˜Ÿ")

    report_lines.append(f"\nğŸ” å„å¡æ± è¯¦ç»†åˆ†æ:")
    report_lines.append("-" * 60)

    for pool_name, stats in results.items():
        this_pool = pool_mapping.get(pool_name, {})
        pool_type_name = this_pool.get('alias', 'æœªçŸ¥å¡æ± ç±»å‹')

        report_lines.append(f"\nğŸ¯ å¡æ± : {pool_name} ({pool_type_name})")
        report_lines.append(f"   â”œâ”€ æ€»æŠ½å–æ¬¡æ•°: {stats['total_pulls']}æ¬¡")
        report_lines.append(f"   â”œâ”€ ç¨€æœ‰åº¦åˆ†å¸ƒ:")
        report_lines.append(f"   â”‚   â”œâ”€ 2æ˜Ÿ: {stats['rarity_counts'][2]}ä¸ª")
        report_lines.append(f"   â”‚   â”œâ”€ 3æ˜Ÿ: {stats['rarity_counts'][3]}ä¸ª")
        report_lines.append(f"   â”‚   â”œâ”€ 4æ˜Ÿ: {stats['rarity_counts'][4]}ä¸ª")
        report_lines.append(f"   â”‚   â”œâ”€ 5æ˜Ÿ: {stats['rarity_counts'][5]}ä¸ª")
        report_lines.append(f"   â”‚   â””â”€ 6æ˜Ÿ: {stats['rarity_counts'][6]}ä¸ª")

        report_lines.append(f"   â”œâ”€ å½“å‰ä¿åº•è¿›åº¦: {stats['pity_progress']}æŠ½æœªå‡º6æ˜Ÿ")

        if stats['rarity_counts'][6] > 0:
            avg_gold_pull = stats['total_pulls'] / stats['rarity_counts'][6]
            report_lines.append(f"   â”œâ”€ å¹³å‡å‡ºé‡‘æŠ½æ•°: {avg_gold_pull:.1f}æŠ½")
            report_lines.append(f"   â””â”€ 6æ˜Ÿè·å–ç‡: {stats['gold_rate']:.2f}%")
        else:
            report_lines.append(f"   â””â”€ å°šæœªè·å¾—6æ˜Ÿ")
    report_lines.append("=" * 60)

    return "\n".join(report_lines)

def analyze_history_file(history_file_path, catalog_data):
    """åˆ†ææŒ‡å®šçš„æŠ½å¡è®°å½•æ–‡ä»¶"""
    try:
        logger = get_logger()
        logger.info(f"å¼€å§‹åˆ†æå†å²è®°å½•æ–‡ä»¶: {history_file_path}")

        # 1. åŠ è½½æŠ½å¡æ•°æ®
        logger.info("æ­£åœ¨åŠ è½½æ•°æ®...")
        with open(history_file_path, 'r', encoding='utf-8') as f:
            gacha_data = json.load(f)

        game_id = gacha_data['info']['game_id']
        game_name = gacha_data['info']['game_name']
        uid = gacha_data['info']['uid']
        logger.info(f"ç”¨æˆ·UID: {uid}")

        # 2. åˆ†ææŠ½å¡æ•°æ®
        logger.info("æ­£åœ¨åˆ†ææŠ½å¡è®°å½•...")
        pool_stats, item_mapping, pool_mapping = analyze_gacha_data(gacha_data, catalog_data)

        # 3. è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        logger.info("æ­£åœ¨è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡...")
        results = calculate_statistics(pool_stats)

        # 4. åˆ›å»ºå¯è§†åŒ–å›¾è¡¨
        logger.info("æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        create_visualizations(game_name, game_id, uid, results)

        # 5. æ–‡å­—åˆ†ææŠ¥å‘Š
        logger.info("ç”Ÿæˆæ–‡å­—åˆ†ææŠ¥å‘Š...")
        report = analysis_report(results, pool_stats, pool_mapping, game_name, uid)
        logger.info(f"{report}")

        logger.info("\nâœ… åˆ†æå®Œæˆï¼")

        # 6. è¿”å›åˆ†æç»“æœ
        return {
            'success': True,
            'pool_stats': pool_stats,
            'report': report,
            'visualizations': {
                'gold_pull_intervals': f'gold_pull_intervals_{game_id}_{uid}.png',
                'rarity_analysis': f'gacha_analysis_{game_id}_{uid}.png'
            }
        }

    except FileNotFoundError as e:
        logger.error(f"æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        return {'success': False, 'error': str(e)}
    except json.JSONDecodeError as e:
        logger.error(f"JSONè§£æé”™è¯¯: {e}")
        return {'success': False, 'error': str(e)}
    except Exception as e:
        logger.error(f"åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return {'success': False, 'error': str(e)}


class GachaAnalyzer:
    """æŠ½å¡è®°å½•åˆ†æå™¨"""
    
    def __init__(self, config_manager):
        self.config_manager = config_manager
        self.logger = get_logger()
    
    def analyze(self, history_file_path, game_id):
        """åˆ†ææŒ‡å®šæ¸¸æˆçš„æŠ½å¡è®°å½•"""
        try:
            # ä½¿ç”¨é…ç½®ç®¡ç†å™¨åŠ è½½ç›®å½•æ•°æ®
            catalog_data = self.config_manager.load_catalog_data(game_id)
            if not catalog_data:
                raise ValueError(f"æ— æ³•åŠ è½½æ¸¸æˆID {game_id} çš„ç›®å½•æ•°æ®")
                
            return analyze_history_file(history_file_path, catalog_data)
        except Exception as e:
            self.logger.error(f"åˆ†æè¿‡ç¨‹å‡ºé”™: {e}")
            return {'success': False, 'error': str(e)}
